{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras version : 2.4.3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "#from keras.utils import np_utils\n",
    "#from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 12\n",
    "np.random.seed(seed)\n",
    "# Import data\n",
    "df = pd.read_csv('training_dataset_remove_duplicates.csv')\n",
    "# Print first 10 samples\n",
    "# print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP_1       0\n",
      "AP_2       0\n",
      "AP_3       0\n",
      "AP_4       0\n",
      "AP_5       0\n",
      "          ..\n",
      "AP_1595    0\n",
      "AP_1596    0\n",
      "AP_1597    0\n",
      "AP_1598    0\n",
      "target     0\n",
      "Length: 1599, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(df.isna().sum()) # No missing values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_row, num_col = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287, 1599)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_row, num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 1598)\n",
      "(287,)\n"
     ]
    }
   ],
   "source": [
    "# Divide data into features X and target (Classes) Y\n",
    "X = df.iloc[:,0:num_col-1]\n",
    "Y = df.iloc[:, num_col-1]\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP_1</th>\n",
       "      <th>AP_2</th>\n",
       "      <th>AP_3</th>\n",
       "      <th>AP_4</th>\n",
       "      <th>AP_5</th>\n",
       "      <th>AP_6</th>\n",
       "      <th>AP_7</th>\n",
       "      <th>AP_8</th>\n",
       "      <th>AP_9</th>\n",
       "      <th>AP_10</th>\n",
       "      <th>...</th>\n",
       "      <th>AP_1589</th>\n",
       "      <th>AP_1590</th>\n",
       "      <th>AP_1591</th>\n",
       "      <th>AP_1592</th>\n",
       "      <th>AP_1593</th>\n",
       "      <th>AP_1594</th>\n",
       "      <th>AP_1595</th>\n",
       "      <th>AP_1596</th>\n",
       "      <th>AP_1597</th>\n",
       "      <th>AP_1598</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>287.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-105.909408</td>\n",
       "      <td>-109.905923</td>\n",
       "      <td>-105.184669</td>\n",
       "      <td>-109.846690</td>\n",
       "      <td>-102.613240</td>\n",
       "      <td>-109.132404</td>\n",
       "      <td>-109.850174</td>\n",
       "      <td>-102.797909</td>\n",
       "      <td>-109.909408</td>\n",
       "      <td>-109.961672</td>\n",
       "      <td>...</td>\n",
       "      <td>-106.062718</td>\n",
       "      <td>-105.247387</td>\n",
       "      <td>-109.947735</td>\n",
       "      <td>-109.954704</td>\n",
       "      <td>-109.825784</td>\n",
       "      <td>-102.386760</td>\n",
       "      <td>-109.954704</td>\n",
       "      <td>-107.933798</td>\n",
       "      <td>-106.703833</td>\n",
       "      <td>-109.759582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.432425</td>\n",
       "      <td>1.593760</td>\n",
       "      <td>13.221779</td>\n",
       "      <td>1.534287</td>\n",
       "      <td>17.050529</td>\n",
       "      <td>5.690431</td>\n",
       "      <td>1.498901</td>\n",
       "      <td>17.226005</td>\n",
       "      <td>1.534731</td>\n",
       "      <td>0.649309</td>\n",
       "      <td>...</td>\n",
       "      <td>11.804478</td>\n",
       "      <td>14.160844</td>\n",
       "      <td>0.885422</td>\n",
       "      <td>0.767366</td>\n",
       "      <td>1.825700</td>\n",
       "      <td>17.492063</td>\n",
       "      <td>0.767366</td>\n",
       "      <td>8.111492</td>\n",
       "      <td>10.860499</td>\n",
       "      <td>2.097627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-40.000000</td>\n",
       "      <td>-83.000000</td>\n",
       "      <td>-41.000000</td>\n",
       "      <td>-92.000000</td>\n",
       "      <td>-41.000000</td>\n",
       "      <td>-59.000000</td>\n",
       "      <td>-92.000000</td>\n",
       "      <td>-29.000000</td>\n",
       "      <td>-84.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.000000</td>\n",
       "      <td>-35.000000</td>\n",
       "      <td>-95.000000</td>\n",
       "      <td>-97.000000</td>\n",
       "      <td>-85.000000</td>\n",
       "      <td>-41.000000</td>\n",
       "      <td>-97.000000</td>\n",
       "      <td>-68.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>-86.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1598 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AP_1        AP_2        AP_3        AP_4        AP_5        AP_6  \\\n",
       "count  287.000000  287.000000  287.000000  287.000000  287.000000  287.000000   \n",
       "mean  -105.909408 -109.905923 -105.184669 -109.846690 -102.613240 -109.132404   \n",
       "std     12.432425    1.593760   13.221779    1.534287   17.050529    5.690431   \n",
       "min   -110.000000 -110.000000 -110.000000 -110.000000 -110.000000 -110.000000   \n",
       "25%   -110.000000 -110.000000 -110.000000 -110.000000 -110.000000 -110.000000   \n",
       "50%   -110.000000 -110.000000 -110.000000 -110.000000 -110.000000 -110.000000   \n",
       "75%   -110.000000 -110.000000 -110.000000 -110.000000 -110.000000 -110.000000   \n",
       "max    -40.000000  -83.000000  -41.000000  -92.000000  -41.000000  -59.000000   \n",
       "\n",
       "             AP_7        AP_8        AP_9       AP_10  ...     AP_1589  \\\n",
       "count  287.000000  287.000000  287.000000  287.000000  ...  287.000000   \n",
       "mean  -109.850174 -102.797909 -109.909408 -109.961672  ... -106.062718   \n",
       "std      1.498901   17.226005    1.534731    0.649309  ...   11.804478   \n",
       "min   -110.000000 -110.000000 -110.000000 -110.000000  ... -110.000000   \n",
       "25%   -110.000000 -110.000000 -110.000000 -110.000000  ... -110.000000   \n",
       "50%   -110.000000 -110.000000 -110.000000 -110.000000  ... -110.000000   \n",
       "75%   -110.000000 -110.000000 -110.000000 -110.000000  ... -110.000000   \n",
       "max    -92.000000  -29.000000  -84.000000  -99.000000  ...  -47.000000   \n",
       "\n",
       "          AP_1590     AP_1591     AP_1592     AP_1593     AP_1594     AP_1595  \\\n",
       "count  287.000000  287.000000  287.000000  287.000000  287.000000  287.000000   \n",
       "mean  -105.247387 -109.947735 -109.954704 -109.825784 -102.386760 -109.954704   \n",
       "std     14.160844    0.885422    0.767366    1.825700   17.492063    0.767366   \n",
       "min   -110.000000 -110.000000 -110.000000 -110.000000 -110.000000 -110.000000   \n",
       "25%   -110.000000 -110.000000 -110.000000 -110.000000 -110.000000 -110.000000   \n",
       "50%   -110.000000 -110.000000 -110.000000 -110.000000 -110.000000 -110.000000   \n",
       "75%   -110.000000 -110.000000 -110.000000 -110.000000 -110.000000 -110.000000   \n",
       "max    -35.000000  -95.000000  -97.000000  -85.000000  -41.000000  -97.000000   \n",
       "\n",
       "          AP_1596     AP_1597     AP_1598  \n",
       "count  287.000000  287.000000  287.000000  \n",
       "mean  -107.933798 -106.703833 -109.759582  \n",
       "std      8.111492   10.860499    2.097627  \n",
       "min   -110.000000 -110.000000 -110.000000  \n",
       "25%   -110.000000 -110.000000 -110.000000  \n",
       "50%   -110.000000 -110.000000 -110.000000  \n",
       "75%   -110.000000 -110.000000 -110.000000  \n",
       "max    -68.000000  -55.000000  -86.000000  \n",
       "\n",
       "[8 rows x 1598 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "REGION1     19\n",
      "REGION10     4\n",
      "REGION11     8\n",
      "REGION12    17\n",
      "REGION13     3\n",
      "REGION14    15\n",
      "REGION15    24\n",
      "REGION16     6\n",
      "REGION17    12\n",
      "REGION18    21\n",
      "REGION2     20\n",
      "REGION3     15\n",
      "REGION4     18\n",
      "REGION5     26\n",
      "REGION6     17\n",
      "REGION7     11\n",
      "REGION8     28\n",
      "REGION9     23\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for class imbalance\n",
    "print(df.groupby(Y).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features within range 0 (minimum) and 1 (maximum)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scale = scaler.fit_transform(X)\n",
    "X_scale = pd.DataFrame(X_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target values as integers(0~17) from string(REGION1, ... REGION18)\n",
    "# Y_en = pd.get_dummies(Y)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "Y_en = encoder.transform(Y)\n",
    "Y_en = to_categorical(Y_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(scaler, open('scaler.pkl', 'wb'))\n",
    "# pickle.dump(encoder, open('label_encoder.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_temp = pickle.load(open('scaler.pkl', 'rb'))\n",
    "en_temp = pickle.load(open('label_encoder.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.66666667, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test scaler saved as pickle file\n",
    "\n",
    "# sc_temp.transform(np.expand_dims(X.values[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 17], dtype=int64)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test encoder saved as pickle file\n",
    "# en_temp.transform(['REGION16', 'REGION9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Keras, convert dataframe to array values (Inbuilt requirement of Keras)\n",
    "X_scale = X_scale.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.66666667, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.76190476, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.92857143, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.66666667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.17391304, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline model. Then use it in Keras Classifier to implement cross validation\n",
    "def baseline_model():\n",
    "    # Create model here\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim = num_col-1, activation = 'relu')) # Rectified Linear Unit Activation Function\n",
    "    model.add(Dense(25, activation = 'relu'))\n",
    "    model.add(Dense(18, activation = 'softmax')) # Softmax for multi-class classification(18 target classes)\n",
    "    # Compile model here\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Keras Classifier and use predefined baseline model\n",
    "estimator = KerasClassifier(build_fn = baseline_model, epochs = 100, batch_size = 10, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold Stratified Cross Validation\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\machinelearning\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, X_scale, Y, cv = kfold)\n",
    "# Result\n",
    "# print(\"Result: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93103451, 0.84482759, 0.92982459, 0.92982459, 0.94736844])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results # cross-validation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15d8a867308>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(X_scale, Y_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790940880775452"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.score(X_scale, Y_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , ..., 0.66666667, 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaler.transform(np.expand_dims(X.values[0], axis=0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction test with 1st row of training set\n",
    "test_data = scaler.transform(np.expand_dims(X.values[7], axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85714286, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction result\n",
    "# estimator.predict(test_data)\n",
    "result = encoder.inverse_transform(estimator.predict(test_data))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REGION3'"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-332-56dbe6554c69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_model.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "# estimator.save('my_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AP_1</th>\n",
       "      <th>AP_2</th>\n",
       "      <th>AP_3</th>\n",
       "      <th>AP_4</th>\n",
       "      <th>AP_5</th>\n",
       "      <th>AP_6</th>\n",
       "      <th>AP_7</th>\n",
       "      <th>AP_8</th>\n",
       "      <th>AP_9</th>\n",
       "      <th>AP_10</th>\n",
       "      <th>...</th>\n",
       "      <th>AP_1589</th>\n",
       "      <th>AP_1590</th>\n",
       "      <th>AP_1591</th>\n",
       "      <th>AP_1592</th>\n",
       "      <th>AP_1593</th>\n",
       "      <th>AP_1594</th>\n",
       "      <th>AP_1595</th>\n",
       "      <th>AP_1596</th>\n",
       "      <th>AP_1597</th>\n",
       "      <th>AP_1598</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-97</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-74</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-82</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-66</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-91</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-78</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-82</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-71</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-61</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-71</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-97</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-74</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-82</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-57</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-95</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-98</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-67</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-64</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-87</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-86</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-71</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-98</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-67</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 1598 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AP_1  AP_2  AP_3  AP_4  AP_5  AP_6  AP_7  AP_8  AP_9  AP_10  ...  \\\n",
       "0    -110  -110  -110  -110   -97  -110  -110   -74  -110   -110  ...   \n",
       "1    -110  -110  -110  -110  -110  -110  -110   -66  -110   -110  ...   \n",
       "2    -110  -110  -110  -110  -110  -110  -110  -110  -110   -110  ...   \n",
       "3    -110  -110  -110  -110  -110  -110  -110   -61  -110   -110  ...   \n",
       "4    -110  -110  -110  -110   -97  -110  -110   -74  -110   -110  ...   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...   \n",
       "282  -110  -110   -57  -110  -110  -110  -110  -110  -110   -110  ...   \n",
       "283  -110  -110   -98  -110  -110  -110  -110  -110  -110   -110  ...   \n",
       "284  -110  -110   -64  -110  -110  -110  -110  -110  -110   -110  ...   \n",
       "285  -110  -110  -110  -110  -110  -110  -110  -110  -110   -110  ...   \n",
       "286  -110  -110   -98  -110  -110  -110  -110  -110  -110   -110  ...   \n",
       "\n",
       "     AP_1589  AP_1590  AP_1591  AP_1592  AP_1593  AP_1594  AP_1595  AP_1596  \\\n",
       "0       -110     -110     -110     -110     -110     -110     -110      -82   \n",
       "1       -110      -91     -110     -110     -110     -110     -110      -78   \n",
       "2       -110      -82     -110     -110     -110     -110     -110      -71   \n",
       "3       -110     -110     -110     -110     -110     -110     -110      -71   \n",
       "4       -110     -110     -110     -110     -110     -110     -110      -82   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "282      -95     -110     -110     -110     -110     -110     -110     -110   \n",
       "283     -110     -110     -110     -110     -110      -67     -110     -110   \n",
       "284      -87     -110     -110     -110     -110     -110     -110     -110   \n",
       "285      -86     -110     -110     -110     -110      -71     -110     -110   \n",
       "286     -110     -110     -110     -110     -110      -67     -110     -110   \n",
       "\n",
       "     AP_1597  AP_1598  \n",
       "0       -110     -110  \n",
       "1       -110     -110  \n",
       "2       -110     -110  \n",
       "3       -110     -110  \n",
       "4       -110     -110  \n",
       "..       ...      ...  \n",
       "282     -110     -110  \n",
       "283     -110     -110  \n",
       "284     -110     -110  \n",
       "285     -110     -110  \n",
       "286     -110     -110  \n",
       "\n",
       "[287 rows x 1598 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      REGION16\n",
       "1      REGION16\n",
       "2      REGION16\n",
       "3      REGION16\n",
       "4      REGION16\n",
       "         ...   \n",
       "282     REGION9\n",
       "283     REGION9\n",
       "284     REGION9\n",
       "285     REGION9\n",
       "286     REGION9\n",
       "Name: target, Length: 287, dtype: object"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now actually make model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim = num_col-1, activation = 'relu')) # Rectified Linear Unit Activation Function\n",
    "model.add(Dense(25, activation = 'relu'))\n",
    "model.add(Dense(18, activation = 'softmax')) # Softmax for multi-class classification(18 target classes)\n",
    "# Compile model here\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 2.2633 - accuracy: 0.3136\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 1.5812 - accuracy: 0.6167\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 1.0519 - accuracy: 0.7909\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.6732 - accuracy: 0.9024\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.4307 - accuracy: 0.9512\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.2937 - accuracy: 0.9756\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.2166 - accuracy: 0.9756\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.1748 - accuracy: 0.9721\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.1411 - accuracy: 0.9756\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.1159 - accuracy: 0.9756\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 0s 517us/step - loss: 0.1061 - accuracy: 0.9686\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.1040 - accuracy: 0.9756\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0882 - accuracy: 0.9791\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0805 - accuracy: 0.9686\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0758 - accuracy: 0.9652\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0741 - accuracy: 0.9721\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0671 - accuracy: 0.9756\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0640 - accuracy: 0.9756\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0676 - accuracy: 0.9686\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0661 - accuracy: 0.9686\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0606 - accuracy: 0.9652\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0578 - accuracy: 0.9756\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0587 - accuracy: 0.9686\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0530 - accuracy: 0.9721\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0545 - accuracy: 0.9721\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0527 - accuracy: 0.9721\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0605 - accuracy: 0.9721\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0574 - accuracy: 0.9721\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0517 - accuracy: 0.9721\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0555 - accuracy: 0.9756\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0546 - accuracy: 0.9686\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0533 - accuracy: 0.9791\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0579 - accuracy: 0.9791\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0602 - accuracy: 0.9686\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0487 - accuracy: 0.9721\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0517 - accuracy: 0.9756\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0489 - accuracy: 0.9686\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0603 - accuracy: 0.9686\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0597 - accuracy: 0.9686\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0469 - accuracy: 0.9756\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0489 - accuracy: 0.9756\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0462 - accuracy: 0.9721\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0494 - accuracy: 0.9756\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0521 - accuracy: 0.9686\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0394 - accuracy: 0.9721\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0488 - accuracy: 0.9756\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 0s 517us/step - loss: 0.0476 - accuracy: 0.9721\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0609 - accuracy: 0.9686\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0524 - accuracy: 0.9686\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0440 - accuracy: 0.9721\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0486 - accuracy: 0.9756\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0490 - accuracy: 0.9721\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0505 - accuracy: 0.9721\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0507 - accuracy: 0.9686\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 0s 621us/step - loss: 0.0505 - accuracy: 0.9652\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 0s 517us/step - loss: 0.0474 - accuracy: 0.9791\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0638 - accuracy: 0.9756\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 0s 517us/step - loss: 0.0480 - accuracy: 0.9652\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0408 - accuracy: 0.9756\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0565 - accuracy: 0.9721\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0429 - accuracy: 0.9721\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0493 - accuracy: 0.9721\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0426 - accuracy: 0.9721\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 0s 621us/step - loss: 0.0503 - accuracy: 0.9721\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0442 - accuracy: 0.9686\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 0s 621us/step - loss: 0.0416 - accuracy: 0.9686\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0556 - accuracy: 0.9721\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0486 - accuracy: 0.9721\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0454 - accuracy: 0.9686\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0472 - accuracy: 0.9721\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0453 - accuracy: 0.9686\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0411 - accuracy: 0.9721\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 0s 621us/step - loss: 0.0497 - accuracy: 0.9721\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 0s 621us/step - loss: 0.0506 - accuracy: 0.9756\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0487 - accuracy: 0.9686\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0425 - accuracy: 0.9756\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0428 - accuracy: 0.9721\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0416 - accuracy: 0.9721\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0412 - accuracy: 0.9686\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0451 - accuracy: 0.9652\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0437 - accuracy: 0.9756\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 0s 517us/step - loss: 0.0498 - accuracy: 0.9756\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0423 - accuracy: 0.9721\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 0s 517us/step - loss: 0.0489 - accuracy: 0.9721\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 0s 517us/step - loss: 0.0332 - accuracy: 0.9791\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0485 - accuracy: 0.9721\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0381 - accuracy: 0.9721\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0489 - accuracy: 0.9721\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0427 - accuracy: 0.9686\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0460 - accuracy: 0.9686\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 0s 517us/step - loss: 0.0446 - accuracy: 0.9652\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0434 - accuracy: 0.9652\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0478 - accuracy: 0.9721\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0376 - accuracy: 0.9686\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0418 - accuracy: 0.9721\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 0s 552us/step - loss: 0.0382 - accuracy: 0.9756\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0402 - accuracy: 0.9686\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 0s 586us/step - loss: 0.0436 - accuracy: 0.9686\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 0s 621us/step - loss: 0.0430 - accuracy: 0.9686\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 0s 621us/step - loss: 0.0393 - accuracy: 0.9721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15d84bf0048>"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_scale, Y_en, epochs = 100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_result = np.argmax(model.predict(test_data).squeeze()) # predict result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REGION3'"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result\n",
    "encoder.inverse_transform([actual_result])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\machinelearning\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\machinelearning\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: keras_model1\\assets\n"
     ]
    }
   ],
   "source": [
    "# model.save('keras_model1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machinelearning] *",
   "language": "python",
   "name": "conda-env-machinelearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
